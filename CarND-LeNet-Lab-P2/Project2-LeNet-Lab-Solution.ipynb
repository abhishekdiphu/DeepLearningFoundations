{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet Lab Solution\n",
    "![LeNet Architecture](lenet.png)\n",
    "Source: Yan LeCun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Load the MNIST data, which comes pre-loaded with TensorFlow.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1110 14:21:59.128036  9632 deprecation.py:323] From <ipython-input-1-fb7a147d8b5e>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1110 14:21:59.131040  9632 deprecation.py:323] From C:\\Users\\abhishek buragohaibn\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W1110 14:21:59.142004  9632 deprecation.py:323] From C:\\Users\\abhishek buragohaibn\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 14:21:59.772707  9632 deprecation.py:323] From C:\\Users\\abhishek buragohaibn\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1110 14:22:00.006002  9632 deprecation.py:323] From C:\\Users\\abhishek buragohaibn\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(28, 28, 1)\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\" , reshape=False)\n",
    "x_train, y_train   =  mnist.train.images, mnist.train.labels\n",
    "x_validation , y_validation = mnist.validation.images, mnist.validation.labels\n",
    "\n",
    "x_test, y_test     = mnist.test.images , mnist.test.labels\n",
    "assert(len(x_train) == len(y_train)) \n",
    "assert(len(x_validation) == len(y_validation))\n",
    "assert(len(x_test) == len(y_test))\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(x_train[0].shape)\n",
    "print(\"Training Set:   {} samples\".format(len(x_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(x_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 1)\n",
      "(32, 32, 1)\n",
      "(32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "##padding with zeros \n",
    "## the input to lenet is 32 32 C\n",
    "## the images are of 28 28 1\n",
    "x_train = np.pad(x_train , ((0,0),(2,2),(2,2),(0,0)) , 'constant')\n",
    "x_validation = np.pad(x_validation ,((0,0),(2,2),(2,2),(0,0)) , 'constant' )\n",
    "x_test       = np.pad(x_test , ((0,0),(2,2),(2,2),(0,0)) , 'constant')\n",
    "\n",
    "print(x_train[0].shape)\n",
    "print(x_validation[0].shape)\n",
    "print(x_test[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Data\n",
    "View a sample from the dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0 , len(x_train))\n",
    "image = x_train[index].squeeze()\n",
    "print(image.shape)\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Data\n",
    "Shuffle the training data.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "x_train , y_train = shuffle(x_train , y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup TensorFlow\n",
    "The EPOCH and BATCH_SIZE values affect the training speed and model accuracy.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "epochs = 10\n",
    "BATCH_SIZE  = 128\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. Since MNIST images are grayscale, C is 1 in this case.\n",
    "\n",
    "Architecture\n",
    "Layer 1: Convolutional. The output shape should be 28x28x6.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Pooling. The output shape should be 14x14x6.\n",
    "\n",
    "Layer 2: Convolutional. The output shape should be 10x10x16.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Pooling. The output shape should be 5x5x16.\n",
    "\n",
    "Flatten. Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using tf.contrib.layers.flatten, which is already imported for you.\n",
    "\n",
    "Layer 3: Fully Connected. This should have 120 outputs.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Layer 4: Fully Connected. This should have 84 outputs.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Layer 5: Fully Connected (Logits). This should have 10 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def LeNet(x):\n",
    "    \n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    \n",
    "    #----layer 1---------#\n",
    "    #32 32 1\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape = (5 ,5 ,1 , 6),\n",
    "                                             mean =mu,\n",
    "                                             stddev = sigma ))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1   = tf.nn.conv2d(x , conv1_W , \n",
    "                           strides=[1,1,1,1], \n",
    "                           padding ='VALID' ) + conv1_b\n",
    "    \n",
    "    #28 28 6\n",
    "    #Activaiton \n",
    "    conv1 =tf.nn.relu(conv1)\n",
    "    \n",
    "    #Maxpooling layer\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize = [1,2,2,1] , \n",
    "                           strides =[1,2,2,1],\n",
    "                           padding = 'VALID')\n",
    "    #14 14 6\n",
    "    \n",
    "    \n",
    "    #-------LAYER 2------#\n",
    "    \n",
    "    \n",
    "    conv2_W =tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16) , \n",
    "                         mean = mu ,\n",
    "                         stddev = sigma))\n",
    "    conv2_b =tf.Variable(tf.zeros(16))\n",
    "    conv2   =tf.nn.conv2d(conv1 , conv2_W , \n",
    "                          strides= [1, 1 ,1 ,1] , padding='VALID') + conv2_b\n",
    "    \n",
    "    #10 10 16\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.max_pool(conv2 , ksize = [1,2,2,1],\n",
    "                              strides = [1,2,2,1],\n",
    "                              padding = 'VALID' )\n",
    "    \n",
    "    #5 5 16\n",
    "    print(conv2.shape)\n",
    "    fc0 = flatten(conv2)\n",
    "    \n",
    "    #400\n",
    "    \n",
    "    fc1_W  = tf.Variable(tf.truncated_normal(shape=(400, 120) ,\n",
    "                                           mean =mu,\n",
    "                                           stddev = sigma))\n",
    "    \n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1   = tf.matmul(fc0 , fc1_W) + fc1_b\n",
    "    \n",
    "    \n",
    "    #120\n",
    "    fc1   = tf.nn.relu(fc1)\n",
    "    \n",
    "    #120\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(120, 84) ,\n",
    "                                           mean =mu,\n",
    "                                           stddev = sigma))\n",
    "    \n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2   = tf.matmul(fc1 , fc2_W) + fc2_b\n",
    "    \n",
    "    \n",
    "    fc2   = tf.nn.relu(fc2)\n",
    "    \n",
    "    # SOLUTION: Layer 5: Fully Connected. Input = 84. Output = 10.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(84, 10), \n",
    "                                             mean = mu, \n",
    "                                             stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(10))\n",
    "    logits    = tf.matmul(fc2  , fc3_W) + fc3_b\n",
    "    \n",
    "     \n",
    "    return logits    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and Labels\n",
    "Train LeNet to classify MNIST data.\n",
    "\n",
    "x is a placeholder for a batch of input images. y is a placeholder for a batch of output labels.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32 , (None , 32,32,1))\n",
    "y = tf.placeholder(tf.int32 , (None))\n",
    "\n",
    "one_hot_y  = tf.one_hot(y , 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 5, 5, 16)\n"
     ]
    }
   ],
   "source": [
    "rate  = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y,\n",
    "                                                       logits = logits)\n",
    "\n",
    "\n",
    "\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer       = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits , 1) , tf.argmax(one_hot_y , 1))\n",
    "\n",
    "accuracy_operation=  tf.reduce_mean(tf.cast(correct_prediction ,tf.float32 ))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "def evaluate(x_data, y_data):\n",
    "    num_examples = len(x_data)\n",
    "    total_accuracy= 0\n",
    "    sess  = tf.get_default_session()\n",
    "    \n",
    "    for offset in range(0, num_examples , BATCH_SIZE):\n",
    "        \n",
    "        batch_x , batch_y =  x_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training..... \n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.966\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.979\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.983\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.988\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.986\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.989\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.985\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.990\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(x_train)\n",
    "    \n",
    "    print(\"training..... \")\n",
    "    \n",
    "    print()\n",
    "    for i  in  range(epochs):\n",
    "        x_train, y_train = shuffle(x_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = x_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(x_validation , y_validation)\n",
    "        \n",
    "        \n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.990\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(x_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
